{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data has already been generated in the multi_mackend_madel_data folder. You can choose not to run this code file as the random data in it may not be reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, pickle, random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn as nn\n",
    "import qiskit\n",
    "from qiskit import QuantumCircuit, execute\n",
    "from qiskit.compiler import transpile\n",
    "from qiskit_aer import AerSimulator, QasmSimulator\n",
    "from qiskit.converters import circuit_to_dag, dag_to_circuit\n",
    "from qiskit.quantum_info import SparsePauliOp, Operator\n",
    "from qiskit.circuit.library import CXGate, RXGate, IGate, ZGate\n",
    "from qiskit.providers.fake_provider import FakeMontreal, FakeLima,FakeGuadalupe,FakeSherbrooke,FakePrague,FakeCairo\n",
    "from blackwater.data.utils import get_backend_properties_v1\n",
    "from qiskit.circuit.random import random_circuit\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置理想和含噪声的后端参数\n",
    "from qiskit.providers.fake_provider import FakeGuadalupe,FakeMontreal,FakeCairo,FakeMumbai,FakeSydney,FakeToronto\n",
    "backend_list = []\n",
    "properties_dict = {}\n",
    "run_config_ideal_list = []\n",
    "run_config_noisy_list = []\n",
    "backend = FakeGuadalupe()\n",
    "backend_list.append(backend)\n",
    "backend = FakeMontreal()\n",
    "backend_list.append(backend)\n",
    "backend = FakeCairo()\n",
    "backend_list.append(backend)\n",
    "backend = FakeMumbai()\n",
    "backend_list.append(backend)\n",
    "backend = FakeSydney()\n",
    "backend_list.append(backend)\n",
    "backend = FakeToronto()\n",
    "backend_list.append(backend)\n",
    "for backend in backend_list:\n",
    "    properties = get_backend_properties_v1(backend)\n",
    "    backend_name = backend.name()\n",
    "    properties_dict[backend_name] = properties\n",
    "    backend_ideal = QasmSimulator() # Noiseless\n",
    "    backend_noisy = AerSimulator.from_backend(backend)\n",
    "    shots = 100000\n",
    "    run_config_ideal = {'shots': shots, 'backend': backend_ideal, 'name': 'ideal'}\n",
    "    run_config_ideal_list.append(run_config_ideal)\n",
    "    run_config_noisy = {'shots': shots, 'backend': backend_noisy, 'name': 'noisy'}\n",
    "    run_config_noisy_list.append(run_config_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Train Data\n",
    "N_FILES = 5\n",
    "N_ENTRIES_PER_FILE = 80\n",
    "for  backend_index,backend in enumerate(backend_list):\n",
    "    backend_name = backend.name()\n",
    "    for i in tqdm_notebook(range(N_FILES)):\n",
    "        entries = []\n",
    "        for index_i in range(N_ENTRIES_PER_FILE):\n",
    "            ciucuit_depth = random.randint(5, 10)\n",
    "            circuit = transpile(\n",
    "                    random_circuit(i+5, ciucuit_depth, measure=True),\n",
    "                    backend,\n",
    "                    optimization_level=3,\n",
    "                )\n",
    "            while(len(circuit)<10):\n",
    "                circuit = transpile(\n",
    "                    random_circuit(i+5, ciucuit_depth, measure=True),\n",
    "                    backend,\n",
    "                    optimization_level=3,\n",
    "                )\n",
    "            # circuit = transpiled_ansatz.bind_parameters(np.random.uniform(-5, 5, (num_params)))\n",
    "            qasm_circuit = circuit.qasm().strip()\n",
    "            with open(f\"./multi_backend_model_data/train_qasm/{backend_name}_{i+5}_qubits_{index_i}.qasm\",'w') as file:\n",
    "                file.write(qasm_circuit)\n",
    "            job_ideal = execute(circuit, **run_config_ideal_list[backend_index])\n",
    "            job_noisy_1 = execute(circuit, **run_config_noisy_list[backend_index])\n",
    "            job_noisy_2 = execute(circuit, **run_config_noisy_list[backend_index])\n",
    "            job_noisy_3 = execute(circuit, **run_config_noisy_list[backend_index])\n",
    "            counts_ideal = dict(job_ideal.result().get_counts()) # dict\n",
    "            counts_noisy_fake_1 = dict(job_noisy_1.result().get_counts()) # dict\n",
    "            counts_noisy_fake_2 = dict(job_noisy_2.result().get_counts()) # dict\n",
    "            counts_noisy_fake_3 = dict(job_noisy_3.result().get_counts()) # dict\n",
    "            to_append = {}\n",
    "            to_append['circuit'] = circuit\n",
    "            to_append['ideal_exp_value'] = counts_ideal\n",
    "            to_append['noisy_exp_values_1'] = counts_noisy_fake_1\n",
    "            to_append['noisy_exp_values_2'] = counts_noisy_fake_2\n",
    "            to_append['noisy_exp_values_3'] = counts_noisy_fake_3\n",
    "            entries.append(to_append)\n",
    "        with open(f\"./multi_backend_model_data/train_data/{backend_name}_{i+5}_qubit.pk\", \"wb\") as pk_file:\n",
    "            pickle.dump(entries, pk_file)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "N_FILES = 2\n",
    "N_ENTRIES_PER_FILE = 20\n",
    "for  backend_index,backend in enumerate(backend_list):\n",
    "    backend_name = backend.name()\n",
    "    for i in tqdm_notebook(range(N_FILES)):\n",
    "        entries = []\n",
    "        for index_i in range(N_ENTRIES_PER_FILE):\n",
    "            ciucuit_depth = random.randint(1, 10)\n",
    "            circuit = transpile(\n",
    "                    random_circuit(i+2, ciucuit_depth, measure=True),\n",
    "                    backend,\n",
    "                    optimization_level=3,\n",
    "                )\n",
    "            while(len(circuit)<10):\n",
    "                circuit = transpile(\n",
    "                    random_circuit(i+2, ciucuit_depth, measure=True),\n",
    "                    backend,\n",
    "                    optimization_level=3,\n",
    "                )\n",
    "            # circuit = transpiled_ansatz.bind_parameters(np.random.uniform(-5, 5, (num_params)))\n",
    "            qasm_circuit = circuit.qasm().strip()\n",
    "            with open(f\"./multi_backend_model_data/test_qasm/{backend_name}_{i+2}_qubits_{index_i}.qasm\",'w') as file:\n",
    "                file.write(qasm_circuit)\n",
    "            job_ideal = execute(circuit, **run_config_ideal_list[backend_index])\n",
    "            job_noisy_1 = execute(circuit, **run_config_noisy_list[backend_index])\n",
    "            job_noisy_2 = execute(circuit, **run_config_noisy_list[backend_index])\n",
    "            job_noisy_3 = execute(circuit, **run_config_noisy_list[backend_index])\n",
    "            counts_ideal = dict(job_ideal.result().get_counts()) # dict\n",
    "            counts_noisy_fake_1 = dict(job_noisy_1.result().get_counts()) # dict\n",
    "            counts_noisy_fake_2 = dict(job_noisy_2.result().get_counts()) # dict\n",
    "            counts_noisy_fake_3 = dict(job_noisy_3.result().get_counts()) # dict\n",
    "            to_append = {}\n",
    "            to_append['circuit'] = circuit\n",
    "            to_append['ideal_exp_value'] = counts_ideal\n",
    "            to_append['noisy_exp_values_1'] = counts_noisy_fake_1\n",
    "            to_append['noisy_exp_values_2'] = counts_noisy_fake_2\n",
    "            to_append['noisy_exp_values_3'] = counts_noisy_fake_3\n",
    "            entries.append(to_append)\n",
    "        with open(f\"./multi_backend_model_data/test_data/{backend_name}_{i+2}_qubit.pk\", \"wb\") as pk_file:\n",
    "            pickle.dump(entries, pk_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for  backend_index,backend in enumerate(backend_list):\n",
    "    backend_name = backend.name()\n",
    "    for qubits in tqdm_notebook(range(13,14)):\n",
    "        entries = []\n",
    "        for MQT_name in MQT_test_list:\n",
    "            qasm_path= f'./MQT_Bench/{MQT_name}_{str(qubits)}.qasm'\n",
    "            try:\n",
    "                circuit = QuantumCircuit.from_qasm_file(qasm_path)\n",
    "            except:\n",
    "                continue\n",
    "            circuit = transpile(\n",
    "                circuit,\n",
    "                backend,\n",
    "                optimization_level=3\n",
    "            )\n",
    "            job_ideal = execute(circuit, **run_config_ideal_list[backend_index])\n",
    "            job_noisy_1 = execute(circuit, **run_config_noisy_list[backend_index])\n",
    "            job_noisy_2 = execute(circuit, **run_config_noisy_list[backend_index])\n",
    "            job_noisy_3 = execute(circuit, **run_config_noisy_list[backend_index])\n",
    "            counts_ideal = dict(job_ideal.result().get_counts()) # dict\n",
    "            counts_noisy_fake_1 = dict(job_noisy_1.result().get_counts()) # dict\n",
    "            counts_noisy_fake_2 = dict(job_noisy_2.result().get_counts()) # dict\n",
    "            counts_noisy_fake_3 = dict(job_noisy_3.result().get_counts()) # dict\n",
    "            to_append = {}\n",
    "            to_append['circuit'] = circuit\n",
    "            to_append['ideal_exp_value'] = counts_ideal\n",
    "            to_append['noisy_exp_values_1'] = counts_noisy_fake_1\n",
    "            to_append['noisy_exp_values_2'] = counts_noisy_fake_2\n",
    "            to_append['noisy_exp_values_3'] = counts_noisy_fake_3\n",
    "            entries.append(to_append)\n",
    "        with open(f\"./multi_backend_model_data/MQT_test/{backend_name}_{qubits}_qubit.pk\", \"wb\") as pk_file:\n",
    "                pickle.dump(entries, pk_file)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
